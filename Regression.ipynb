{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "10a7b2d2-5fa6-454b-b524-527591e3c6fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Read data\n",
    "df = pd.read_excel(\"Actuals.xlsx\")\n",
    "\n",
    "# Separate features and target variable\n",
    "y1 = df['Load (kW)']  # Target variable\n",
    "X1 = df.drop(columns=['Load (kW)'])  # Features\n",
    "\n",
    "# Extract relevant information from datetime feature\n",
    "X1['Year'] = X1['Time'].dt.year\n",
    "X1['Month'] = X1['Time'].dt.month\n",
    "X1['Day'] = X1['Time'].dt.day\n",
    "X1['Hour'] = X1['Time'].dt.hour\n",
    "# Drop the original datetime feature\n",
    "X1.drop(columns=['Time'], inplace=True)\n",
    "\n",
    "# Remove leading and trailing whitespaces from column names\n",
    "X1.columns = X1.columns.str.strip()\n",
    "\n",
    "# Define numerical and categorical features\n",
    "numeric_features = ['Pressure_kpa', 'Cloud Cover (%)', 'Humidity (%)', 'Temperature (C)', 'Wind Direction (deg)', 'Wind Speed (kmh)', 'Year', 'Month', 'Day', 'Hour']\n",
    "categorical_features = []\n",
    "\n",
    "# Define preprocessing steps for numerical and categorical features\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('onehot', OneHotEncoder())\n",
    "])\n",
    "\n",
    "# Combine preprocessing steps\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ])\n",
    "\n",
    "# Apply preprocessing to the data\n",
    "try:\n",
    "    X_preprocessed = preprocessor.fit_transform(X1)\n",
    "except KeyError as e:\n",
    "    print(f\"KeyError occurred: {e}\")\n",
    "    print(\"Ensure all columns specified in numeric_features and categorical_features are present in the DataFrame.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3b2e6b3-a216-4bc4-b1b2-7fe9c7a287fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Features to remove\n",
    "features_to_remove = ['Wind Direction (deg)','Day', 'Year', 'Month','Humidity (%)']\n",
    "\n",
    "\n",
    "# Remove the specified columns from X_preprocessed\n",
    "columns_to_remove = [numeric_features.index(feature) for feature in features_to_remove]\n",
    "X_preprocessed = np.delete(X_preprocessed, columns_to_remove, axis=1)\n",
    "\n",
    "# Update the numeric_features list\n",
    "numeric_features = [feature for feature in numeric_features if feature not in features_to_remove]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da0ffc34-cf63-4a58-aa03-b94692e2cfd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Features to remove\n",
    "features_to_remove = ['Wind Direction (deg)','Day', 'Year', 'Month','Humidity (%)']\n",
    "\n",
    "\n",
    "# Remove the specified columns from X_preprocessed\n",
    "columns_to_remove = [numeric_features.index(feature) for feature in features_to_remove]\n",
    "X_preprocessed = np.delete(X_preprocessed, columns_to_remove, axis=1)\n",
    "\n",
    "# Update the numeric_features list\n",
    "numeric_features = [feature for feature in numeric_features if feature not in features_to_remove]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3601850-36f7-4298-b437-aa73c83cbe95",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Split the preprocessed data and normalized target variable into train and test sets\n",
    "X1_train, X1_test, y1_train, y1_test = train_test_split(X_preprocessed, y_normalized, test_size=0.1, random_state=42)\n",
    "\n",
    "\n",
    "# Update model instantiation with best parameters\n",
    "reg_model = linear_model.LinearRegression(copy_X=True, fit_intercept=False, positive=False)\n",
    "\n",
    "# Fit the model with updated parameters\n",
    "reg_model.fit(X1_train, y1_train)\n",
    "\n",
    "\n",
    "# Make predictions on the test data\n",
    "y1_pred = reg_model.predict(X1_test)\n",
    "\n",
    "# Flatten the predicted values to 1-dimensional array\n",
    "y1_pred_flat = y1_pred.flatten()\n",
    "\n",
    "# Compare the predicted values with the actual values\n",
    "comparison1 = pd.DataFrame({'Actual': y1_test.flatten(), 'Predicted': y1_pred_flat})\n",
    "print(comparison1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79b01b4a-8bb1-46bc-b945-afa943129a0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "\n",
    "# Calculate R-squared value\n",
    "r_squared = r2_score(y1_test, y1_pred)\n",
    "\n",
    "# Calculate Mean Squared Error (MSE)\n",
    "mse = mean_squared_error(y1_test, y1_pred)\n",
    "\n",
    "# Format the output to display up to two decimal points\n",
    "formatted_r_squared = \"{:.2f}\".format(r_squared)\n",
    "formatted_mse = \"{:.2f}\".format(mse)\n",
    "\n",
    "print(\"R-squared score:\", formatted_r_squared)\n",
    "print(\"Mean Squared Error (MSE):\", formatted_mse)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b115e4d5-1be5-43ea-9dcc-42d9bb7be297",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the coefficients of the linear regression model\n",
    "coefficients = reg_model.coef_[0]\n",
    "\n",
    "# Get the absolute values of the coefficients for better comparison\n",
    "abs_coefficients = np.abs(coefficients)\n",
    "\n",
    "# Create a DataFrame to store feature names and their corresponding coefficients\n",
    "feature_coefficients = pd.DataFrame({\n",
    "    'Feature': np.array(numeric_features),  # Update with remaining numeric features\n",
    "    'Coefficient': abs_coefficients\n",
    "})\n",
    "\n",
    "# Sort the features based on their coefficients in descending order\n",
    "feature_coefficients = feature_coefficients.sort_values(by='Coefficient', ascending=False)\n",
    "\n",
    "# Print the features with their coefficients\n",
    "print(\"Features with Discriminating Power (Ranked by Coefficient):\")\n",
    "print(feature_coefficients)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c5d006e-c62a-4ef7-b61d-354f301d6c43",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "# Define the hyperparameters grid\n",
    "param_grid = {\n",
    "    'fit_intercept': [True, False],\n",
    "    'copy_X': [True, False],\n",
    "    'positive': [True, False]\n",
    "}\n",
    "\n",
    "# Initialize GridSearchCV\n",
    "grid_search = GridSearchCV(reg_model, param_grid, cv=5, scoring='neg_mean_squared_error', verbose=1)\n",
    "\n",
    "# Perform grid search\n",
    "grid_search.fit(X1_train, y1_train)\n",
    "\n",
    "# Print the best parameters found\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "\n",
    "# Print the best MSE found\n",
    "print(\"Best Mean Squared Error:\", -grid_search.best_score_)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
